{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "from cs104 import *\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Midterm Scores\n",
    "\n",
    "Was Lab Section 3 graded differently than that other lab sections, or could their low average score be attributed to the random chance of the students assigned to that section? \n",
    "\n",
    "In this dataset, each **row** (observation) is a single student. There are 4 lab sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = Table().read_table(\"data/scores_by_section.csv\")\n",
    "scores.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many students in each section? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.group(\"Section\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the mean Midterm score across each section? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.group(\"Section\", np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab section 3's observed average score on the midterm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_scores = scores.where(\"Section\", 3).column(\"Midterm\")\n",
    "observed_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_average = np.mean(observed_scores)\n",
    "observed_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed sample size is the number of students in Lab Section 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_sample_size = scores.where(\"Section\", 3).num_rows\n",
    "observed_sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null hypothesis model**:  mean of the population \n",
    "\n",
    "**Null hypothesis restated**: The mean in *any* sample should be close to the mean in the population (the whole class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_hypothesis_model_parameter = np.mean(scores.column(\"Midterm\"))\n",
    "null_hypothesis_model_parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between Lab Section 3's average midterm score and the average midterm score across *all* students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_midterm_statistic = abs(observed_average - null_hypothesis_model_parameter)\n",
    "observed_midterm_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstraction: Let's create a function that calculates a statistic as the absolute difference between the mean of a sample and the mean of a population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic_abs_diff_means(sample):\n",
    "    \"\"\"Return the absolute difference in means between a sample and a population\"\"\"\n",
    "    return np.abs(np.mean(sample) - null_hypothesis_model_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_midterm_statistic = statistic_abs_diff_means(observed_scores)\n",
    "observed_midterm_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate a sample from teh null hypothesis, we'll sample without replacement to represent a different grouping of students into sections.  \n",
    "\n",
    "For example, these \"could have been\" Section 3 (if it was sample size 5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = scores.sample(5, with_replacement=False)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample.column(\"Midterm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put this into a function we can later put into `simulate_sample_statistic`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_scores(sample_size):\n",
    "    \"\"\"\n",
    "    Sampling scores with replacement \n",
    "    \n",
    "    Note: we're using with_replacement=False here because we don't \n",
    "    want to sample the same student's score twice.\n",
    "    \"\"\"\n",
    "    return scores.sample(sample_size, with_replacement=False).column(\"Midterm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_scores(observed_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simulated_midterm_statistics = simulate_sample_statistic(sample_scores, \n",
    "                                         observed_sample_size, \n",
    "                                         statistic_abs_diff_means, \n",
    "                                         5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Table().with_columns(\"Statistic: abs(sample mean - population mean)\", \n",
    "                               simulated_midterm_statistics)\n",
    "plot = results.hist(title=\"Null hypothesis empirical distribution\")    \n",
    "plot.dot(observed_midterm_statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculating p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simulated_and_observed_statistics(simulated_statistics, observed_statistic):\n",
    "    \"\"\"\n",
    "    Plots the empirical distribution of the simulated statistics, along with\n",
    "    the observed data's statistic, highlighting the tail in yellow.\n",
    "    \"\"\"\n",
    "    results = Table().with_columns(\"Statistic: abs(sample mean - population mean)\", \n",
    "                                   simulated_statistics)\n",
    "    plot = results.hist(left_end=observed_statistic, title=\"Null hypothesis empirical distribution\")\n",
    "    plot.dot(observed_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulated_and_observed_statistics(simulated_midterm_statistics, observed_midterm_statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supposed we observed other observed statistics: 0.3, 1.5, and 2.7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Figure(1,3):\n",
    "    plot_simulated_and_observed_statistics(simulated_midterm_statistics, 0.3)\n",
    "    plot_simulated_and_observed_statistics(simulated_midterm_statistics, 1.5)\n",
    "    plot_simulated_and_observed_statistics(simulated_midterm_statistics, 2.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating p-values:**\n",
    "Let's compute the proportion of the histogram that is colored yellow. This captures the proportion of the simulated samples under the null hypothesis that are more unlikely than the observed data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do it first for our midterm example, and then generalize to a function we can use to compute p-values for any test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_midterm_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(simulated_midterm_statistics >= observed_midterm_statistic) / len(simulated_midterm_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def empirical_pvalue(null_statistics, observed_statistic): \n",
    "    \"\"\"\n",
    "    Return the proportion of the null statistics that are greater than \n",
    "    or equal to the observed statistic.\n",
    "    \"\"\"\n",
    "    return np.count_nonzero(null_statistics >= observed_statistic) / len(null_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empirical_pvalue(simulated_midterm_statistics, observed_midterm_statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Impact of Sample Size on p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that as our sample size increases, we observe less variability in our samples.\n",
    "\n",
    "Here's a visualizaion showing the **Null hypothesis empirical distribution** for different sample sizes.  Note how the p-value changes as the sample size changes due to that effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def visualize_p_value_and_sample_size(sample_size):\n",
    "    \n",
    "    simulated_midterm_statistics = simulate_sample_statistic(sample_scores, \n",
    "                                         sample_size, \n",
    "                                         statistic_abs_diff_means, \n",
    "                                         1000)\n",
    "    \n",
    "    results = Table().with_columns(\"Statistic: abs(sample mean - class mean)\", \n",
    "                                   simulated_midterm_statistics)\n",
    "    plot = results.hist(left_end=observed_midterm_statistic,bins=np.arange(0,6,0.2)) \n",
    "\n",
    "    plot.dot(observed_midterm_statistic)\n",
    "    plot.set_ylim(0,2)\n",
    "    \n",
    "    pvalue = empirical_pvalue(simulated_midterm_statistics, observed_midterm_statistic)\n",
    "    plot.set_title('sample-size = ' + str(sample_size) + '\\np-value = '+str(pvalue))\n",
    "    \n",
    "\n",
    "interact(visualize_p_value_and_sample_size, \n",
    "         sample_size=Slider(5,80))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
